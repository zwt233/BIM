{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result dir: result_cora\n",
      "Cuda: True\n",
      "\n",
      "Upload cora dataset.\n",
      "\n",
      "Training Node numbers: [20, 20, 20, 20, 2, 2, 2] Sum: 86\n",
      "Validation Node numbers: [57, 34, 75, 164, 75, 67, 28] Sum: 500\n",
      "Testing Node numbers: [143, 74, 155, 317, 149, 101, 61] Sum: 1000\n",
      "Unlabeled Node numbers: [131, 89, 168, 317, 182, 110, 71] Sum: 1068\n",
      "Stage:0 f1_val: 0.6039 f1_test: 0.5770\n",
      "Stage:1 f1_val: 0.7167 f1_test: 0.6794\n",
      "Stage:2 f1_val: 0.7442 f1_test: 0.7072\n",
      "Stage:3 f1_val: 0.7551 f1_test: 0.7064\n",
      "Stage:4 f1_val: 0.7612 f1_test: 0.7113\n",
      "Stage:5 f1_val: 0.7637 f1_test: 0.7064\n",
      "Stage:6 f1_val: 0.7516 f1_test: 0.6898\n"
     ]
    }
   ],
   "source": [
    "from pymodule import *\n",
    "from utils import *\n",
    "from network import *\n",
    "\n",
    "\n",
    "def train(model, optimizer, record,args, model_name):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(features, adj, flag=0)\n",
    "    if args.hard_label==True:\n",
    "        loss_CEloss=Sample_weighted_CEloss()\n",
    "        if args.cuda==True:\n",
    "            loss_CEloss=loss_CEloss.cuda()\n",
    "        loss_train = loss_CEloss(output[idx_train], labels_onehot[idx_train],loss_weight[idx_train])\n",
    "    else:  \n",
    "        loss_CEloss=CEloss()\n",
    "        if args.cuda==True:\n",
    "            loss_CEloss=loss_CEloss.cuda()\n",
    "        loss_train = loss_CEloss(output[idx_train], labels_softonehot[idx_train])\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        model.eval()\n",
    "        output = model(features, adj, flag=1)\n",
    "    f1_val = f1_score(labels[idx_val].cpu(),torch.max(output[idx_val,:],1)[1].cpu(), average=\"macro\")\n",
    "\n",
    "    if f1_val > args.max_f1_val:\n",
    "        args.max_f1_val = f1_val\n",
    "\n",
    "        torch.save(model.state_dict(),model_name)\n",
    "        f1_test = f1_score(labels[idx_test].cpu(),torch.max(output[idx_test,:],1)[1].cpu(), average=\"macro\") \n",
    "        acc_test = accuracy(output[idx_test].cpu(), labels[idx_test].cpu())\n",
    "        auc_test=roc_auc_score(labels[idx_test].cpu(),output[idx_test,:].cpu().detach().numpy(), average=\"macro\",multi_class='ovo')\n",
    "\n",
    "        \n",
    "        record[f1_val.item()] = [f1_val.item(), f1_test.item(), acc_test.item(), auc_test.item()]\n",
    "\n",
    "def RF_calculation():\n",
    "    idx_nodes={}\n",
    "    activation={}\n",
    "    for i in range(class_num):\n",
    "        idx_nodes[i]=[]\n",
    "        activation[i]=[]\n",
    "    for i in idx_train_round_0:\n",
    "        idx_nodes[int(labels[i])].append(int(i))\n",
    "    for i in range(class_num):\n",
    "        if i==0:\n",
    "            activation=adj_probability[idx_nodes[i],:].sum(axis=0)\n",
    "        else:\n",
    "            activation=np.row_stack((activation, adj_probability[idx_nodes[i],:].sum(axis=0)))\n",
    "\n",
    "    # Add new nodes\n",
    "    if idx_train_buffer.size!=0:\n",
    "        for idx in idx_train_buffer:\n",
    "            activation=activation+(confidence_score[idx,:].reshape(-1,1))*adj_probability[idx,:]\n",
    "\n",
    "    RF_num=activation_vec(activation, args.T_influence)\n",
    "    RF_num_all=activation_vec_all(activation, args.T_influence)\n",
    "    return RF_num,RF_num_all, activation\n",
    "\n",
    "def search_nodes():\n",
    "    dif=[]\n",
    "    dif_class=[]   \n",
    "    activation_buf={}\n",
    "    RF_num_buf={}\n",
    "    RF_num_all_buf={}\n",
    "    class_idx=[]\n",
    "    normal_entropy={}\n",
    "    RF_para_buf={}\n",
    "    idx_search=[]\n",
    "\n",
    "    for i in idx_unlabeled:\n",
    "        con_score=confidence_score[i].max(0)\n",
    "        if con_score>=args.T_confidence:\n",
    "            idx_search.append(i)\n",
    "\n",
    "\n",
    "    for i in range(len(idx_search)):\n",
    "        activation_buf[i]=[]\n",
    "        idx=idx_search[i]\n",
    "        class_idx.append(np.argmax(confidence_score[idx]))\n",
    "        if  nodes[class_idx[i]]<args.max_nodes_num:\n",
    "            activation_buf[i]=activation+(confidence_score[idx].reshape(-1,1)*adj_probability[idx,:])\n",
    "            RF_num_buf[i]=activation_vec(activation_buf[i], args.T_influence)\n",
    "            RF_num_all_buf[i]=activation_vec_all(activation_buf[i], args.T_influence)\n",
    "            normal_entropy[i] = cal_entropy(RF_num_buf[i])\n",
    "            RF_para_buf[i]=(RF_num_all_buf[i]/labels.shape[0])+args.alpha*normal_entropy[i]\n",
    "            if (RF_num_buf[i]==RF_num and RF_num_all_buf[i]-RF_num_all==0) or (RF_para_buf[i]<=RF_para):\n",
    "                activation_buf[i]=-1\n",
    "                RF_num_buf[i]=-1\n",
    "                RF_num_all_buf[i]=-1\n",
    "                dif.append(-1000000)\n",
    "            else:\n",
    "                dif_class.append(i)\n",
    "                dif.append(RF_para_buf[i])\n",
    "        else:\n",
    "            activation_buf[i]=-1\n",
    "            RF_num_buf[i]=-1\n",
    "            RF_num_all_buf[i]=-1\n",
    "            dif.append(-1000000)\n",
    "    return np.array(dif), activation_buf, np.array(dif_class).astype(int), RF_num_buf, RF_num_all_buf, class_idx, normal_entropy, RF_para_buf, idx_search\n",
    "\n",
    "def best_node_cal():\n",
    "\n",
    "    max_dif=np.max(dif[dif_class])\n",
    "    dif_best_idx=np.argmax(dif)\n",
    "    pseudo_node[class_idx[dif_best_idx]]+=1\n",
    "    nodes[class_idx[dif_best_idx]]+=1\n",
    "\n",
    "    \n",
    "    best_idx=idx_search[dif_best_idx]\n",
    "    global idx_unlabeled\n",
    "    del_dif_idx=np.where(idx_unlabeled==best_idx)[0]\n",
    "\n",
    "    # Select the max RF increase node\n",
    "    global idx_train_buffer\n",
    "    idx_train_buffer=np.append(idx_train_buffer,best_idx).astype(np.int64)\n",
    "\n",
    "    # # Hard label\n",
    "    ones=np.ones([class_num])\n",
    "    ones[np.argmax(confidence_score[best_idx])]=0\n",
    "    labels_onehot[best_idx,:]=torch.tensor((1-ones))\n",
    "    labels[best_idx]=np.argmax(confidence_score[best_idx])\n",
    "    loss_weight[best_idx]=torch.tensor(confidence_score[best_idx,np.argmax(confidence_score[best_idx])])\n",
    "    # # Soft label\n",
    "    labels_softonehot[best_idx,:]=torch.tensor(confidence_score[best_idx,:])\n",
    "\n",
    "    activation=activation_buf[dif_best_idx]\n",
    "    RF_num=RF_num_buf[dif_best_idx]\n",
    "    RF_num_all=RF_num_all_buf[dif_best_idx]\n",
    "    idx_unlabeled=np.delete(idx_unlabeled, del_dif_idx) \n",
    "    entropy = normal_entropy[dif_best_idx]\n",
    "    RF_para = RF_para_buf[dif_best_idx]\n",
    "    return RF_num, RF_num_all, activation, entropy, RF_para\n",
    "\n",
    "def set_cuda():\n",
    "    global model, features, adj, labels, idx_test, idx_train, idx_val, idx_train_original, labels_onehot, loss_weight\n",
    "    model = model.cuda()\n",
    "    features = features.cuda()\n",
    "    adj = adj.cuda()\n",
    "    labels = labels.cuda()\n",
    "    idx_train = idx_train.cuda()\n",
    "    idx_val = idx_val.cuda()\n",
    "    idx_test = idx_test.cuda()\n",
    "    labels_onehot = labels_onehot.cuda()\n",
    "    loss_weight= loss_weight.cuda()\n",
    "    idx_train_original=idx_train_original.cuda()\n",
    "\n",
    "def set_cpu():\n",
    "    global labels, labels_onehot, loss_weight, idx_train \n",
    "    labels = labels.cpu()\n",
    "    labels_onehot=labels_onehot.cpu()\n",
    "    idx_train = idx_train.cpu()\n",
    "    loss_weight= loss_weight.cpu()  \n",
    "    \n",
    "\n",
    "\n",
    "#######################################################################################################\n",
    "\n",
    "parser = get_parser()\n",
    "args = parser.parse_known_args()[0]\n",
    "\n",
    "args.result_dir='result_'+str(args.dataset)\n",
    "args.train_initial_model=True\n",
    "print(\"\\nResult dir:\", args.result_dir)\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "print('Cuda:', args.cuda)\n",
    "result_dir=set_file_name(args)\n",
    "csv_file=result_dir+'result_'+args.dataset+'.csv'\n",
    "\n",
    "with open(csv_file,'w+',newline='')as f:\n",
    "    fieldnames = {'f1_test','acc_test','auc_test'}\n",
    "    writer = csv.DictWriter(f,fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "para_list={}\n",
    "para_result={}\n",
    "time_begin=time.time() \n",
    "\n",
    "# Dataloader\n",
    "adj, features, labels, labels_onehot, idx_train, idx_val, idx_test, idx_unlabeled, adj_original= load_data(args=args,path=\"../data\")\n",
    "sample_num=labels_onehot.size()[0]\n",
    "class_num=labels_onehot.size()[1]\n",
    "\n",
    "idx_train_original=idx_train.clone()\n",
    "labels_softonehot=labels_onehot.clone()\n",
    "loss_weight=torch.ones(sample_num)\n",
    "final_record={}\n",
    "nodes=np.zeros([class_num]) \n",
    "for i in range(class_num):\n",
    "    nodes[i]=sum(labels_onehot[idx_train][:,i]) \n",
    "\n",
    "# # Train stage 0\n",
    "#Model and optimizer\n",
    "set_seed(args.seed)\n",
    "model = GCN(nfeat=features.shape[1],nhid=args.nhid,nclass=labels.max().item() +1,dropout=args.dropout)\n",
    "optimizer = optim.Adam(model.parameters(),lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "args.max_f1_val=0.1\n",
    "if args.train_initial_model==True:\n",
    "    record = {}\n",
    "    if args.cuda==True:\n",
    "        set_cuda()\n",
    "    for epoch in range(args.epochs):\n",
    "        train(model,optimizer,record,args,model_name=result_dir+\"model_0.pth\")\n",
    "    if args.cuda==True:\n",
    "        set_cpu()        \n",
    "    print_fin_result(args,record,stage=0)\n",
    "    final_record = board_log(args, record, final_record, opt=0)\n",
    "    model.load_state_dict(torch.load(result_dir+\"model_0.pth\",map_location='cpu'))\n",
    "else:     \n",
    "    model.load_state_dict(torch.load(\"model_0.pth\",map_location='cpu'))\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        output = model(features, adj, flag=1)\n",
    "    f1_val = f1_score(labels[idx_val],torch.max(output[idx_val,:],1)[1], average=\"macro\")\n",
    "    f1_test = f1_score(labels[idx_test],torch.max(output[idx_test,:],1)[1], average=\"macro\")\n",
    "    print('Stage:0','f1_val: {:.4f}'.format(f1_val),'f1_test: {:.4f}'.format(f1_test))\n",
    "    final_record[0]=[f1_val.item(), f1_test.item()]\n",
    " \n",
    "\n",
    "# # Pseudo label learning\n",
    "# Probability matrix\n",
    "adj_probability=jump_probability(adj_original+sp.eye(adj_original.shape[0]),power=2)\n",
    "idx_train_round_0=idx_train.clone()\n",
    "idx_train_buffer=np.array([])\n",
    "\n",
    "# Initail RF calculation\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    confi= model(features, adj, flag=1)\n",
    "    confidence=confi.cpu()\n",
    "confidence_score=np.array(confidence.clone())\n",
    "RF_num_0, RF_num_all_0, activation = RF_calculation() \n",
    "entropy_0 = cal_entropy(RF_num_0)\n",
    "RF_para_0=RF_num_all_0/labels.shape[0]+args.alpha*entropy_0\n",
    "\n",
    "\n",
    "pseudo_node=np.zeros([class_num]) \n",
    "RF_num=RF_num_0\n",
    "RF_num_all=RF_num_all_0\n",
    "RF_para=RF_para_0\n",
    "while 1:\n",
    "    dif, activation_buf, dif_class, RF_num_buf, RF_num_all_buf, class_idx, normal_entropy, RF_para_buf, idx_search = search_nodes()\n",
    "    if dif_class.size>0:\n",
    "        RF_num, RF_num_all, activation, entropy, RF_para = best_node_cal()\n",
    "    else:\n",
    "        break\n",
    "\n",
    "idx_train=torch.tensor(np.append(idx_train_round_0, torch.tensor(idx_train_buffer,dtype=int)))\n",
    "\n",
    "# # Train stage 1\n",
    "record = {}\n",
    "args.max_f1_val=0.1\n",
    "model_name=result_dir+\"model_1.pth\"\n",
    "if args.train_new_model==True:\n",
    "    set_seed(args.seed)\n",
    "    model = GCN(nfeat=features.shape[1],nhid=args.nhid,nclass=labels.max().item() +1,dropout=args.dropout)\n",
    "    optimizer = optim.Adam(model.parameters(),lr=args.lr, weight_decay=args.weight_decay)\n",
    "if args.cuda==True:\n",
    "    set_cuda()\n",
    "for epoch in range(args.epochs):\n",
    "    train(model, optimizer, record, args, model_name=model_name)\n",
    "if args.cuda==True:\n",
    "    set_cpu()\n",
    "print_fin_result(args,record,stage=1)\n",
    "final_record = board_log(args, record, final_record, opt=1)\n",
    "\n",
    "\n",
    "\n",
    "# # Train iteratively\n",
    "confidence={}\n",
    "for opt_num in range(args.optimize_num-1):\n",
    "    confidence[opt_num]=[]\n",
    "    # Initail RF calculation\n",
    "    model_name=result_dir+\"model_\"+str(opt_num+1)+\".pth\"\n",
    "    model.load_state_dict(torch.load(model_name))\n",
    "    if args.cuda==True:\n",
    "        model.cuda()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        confi= model(features, adj, flag=1)\n",
    "        confidence[opt_num]=confi.cpu()\n",
    "\n",
    "    for i in range(opt_num+1):\n",
    "        if i==0:\n",
    "            confidence_score=np.array(confidence[i].clone())\n",
    "        else:\n",
    "            confidence_score=confidence_score+np.array(confidence[i].clone())\n",
    "    confidence_score=confidence_score/(opt_num+1)\n",
    "\n",
    "    RF_num_0, RF_num_all_0, activation = RF_calculation()\n",
    "    entropy_0 = cal_entropy(RF_num_0)\n",
    "    RF_para_0=RF_num_all_0/labels.shape[0]+args.alpha*entropy_0 \n",
    "    for change_idx in idx_train_buffer:\n",
    "        loss_weight[change_idx]=torch.tensor(confidence_score[change_idx,np.argmax(confidence_score[change_idx])]) \n",
    "\n",
    "    RF_num=RF_num_0\n",
    "    RF_num_all=RF_num_all_0\n",
    "    RF_para=RF_para_0\n",
    "    pseudo_node=np.zeros([class_num]) \n",
    "    while 1:\n",
    "        dif, activation_buf, dif_class, RF_num_buf, RF_num_all_buf, class_idx, normal_entropy, RF_para_buf, idx_search = search_nodes()\n",
    "        if len(dif_class)>0:\n",
    "            RF_num, RF_num_all, activation, entropy, RF_para = best_node_cal()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    idx_train=torch.tensor(np.append(idx_train_round_0, torch.tensor(idx_train_buffer,dtype=int)))\n",
    "\n",
    "    # Training\n",
    "    record = {}\n",
    "    \n",
    "    model_name=result_dir+\"model_\"+str(opt_num+2)+\".pth\"\n",
    "    args.max_f1_val=0.1\n",
    "    if args.train_new_model==True:\n",
    "        set_seed(args.seed)\n",
    "        model = GCN(nfeat=features.shape[1],nhid=args.nhid,nclass=labels.max().item() +1,dropout=args.dropout)\n",
    "        optimizer = optim.Adam(model.parameters(),lr=args.lr, weight_decay=args.weight_decay)\n",
    "    if args.cuda==True:\n",
    "        set_cuda()        \n",
    "    for epoch in range(args.epochs):\n",
    "        train(model, optimizer, record, args, model_name=model_name)\n",
    "    if args.cuda==True:\n",
    "        set_cpu()\n",
    "    print_fin_result(args,record,stage=opt_num+2)\n",
    "    final_record = board_log(args, record, final_record, opt=opt_num+2)\n",
    "val_score=[]\n",
    "for i in range(len(final_record)):\n",
    "    val_score.append(final_record[i][0])\n",
    "best_stage = np.argmax(val_score)\n",
    "\n",
    "write_record=  {'f1_test': round(final_record[best_stage][1],3), 'acc_test':round(final_record[best_stage][2],3), 'auc_test':round(final_record[best_stage][3],3)}\n",
    "\n",
    "with open(csv_file,'a+',newline='')as f:\n",
    "    fieldnames = {'f1_test','acc_test','auc_test'}\n",
    "    writer = csv.DictWriter(f,fieldnames=fieldnames)\n",
    "    writer.writerow(write_record)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('GNN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b62820f63f0320e0c7cefc7b2bedc14d322aa683bb55123f9d27395f98da1968"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
